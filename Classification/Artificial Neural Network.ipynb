{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0424d7c",
   "metadata": {},
   "source": [
    "<h1 style = \"font-size:3rem;color:DarkCyan\">Train Classifier Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38ff13fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd # for data importing\n",
    "import sklearn # for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a34c372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sf</th>\n",
       "      <th>mfcc</th>\n",
       "      <th>scon</th>\n",
       "      <th>zcr</th>\n",
       "      <th>rms</th>\n",
       "      <th>tg</th>\n",
       "      <th>label</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009266</td>\n",
       "      <td>-16.176497</td>\n",
       "      <td>20.150281</td>\n",
       "      <td>0.238694</td>\n",
       "      <td>0.042907</td>\n",
       "      <td>0.122623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>clap00.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.060073</td>\n",
       "      <td>-15.045925</td>\n",
       "      <td>20.220686</td>\n",
       "      <td>0.181085</td>\n",
       "      <td>0.091807</td>\n",
       "      <td>0.012034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>clap01.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027080</td>\n",
       "      <td>-18.072697</td>\n",
       "      <td>20.386491</td>\n",
       "      <td>0.186275</td>\n",
       "      <td>0.060785</td>\n",
       "      <td>0.035546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>clap02.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.053378</td>\n",
       "      <td>-29.048000</td>\n",
       "      <td>23.282097</td>\n",
       "      <td>0.261476</td>\n",
       "      <td>0.059042</td>\n",
       "      <td>0.148375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>clap03.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002444</td>\n",
       "      <td>-28.880560</td>\n",
       "      <td>21.106727</td>\n",
       "      <td>0.120479</td>\n",
       "      <td>0.012474</td>\n",
       "      <td>0.073228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>clap04.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.035142</td>\n",
       "      <td>-18.951557</td>\n",
       "      <td>21.133549</td>\n",
       "      <td>0.178874</td>\n",
       "      <td>0.022656</td>\n",
       "      <td>0.015246</td>\n",
       "      <td>3.0</td>\n",
       "      <td>snare_37.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.022006</td>\n",
       "      <td>-19.046724</td>\n",
       "      <td>20.261291</td>\n",
       "      <td>0.146732</td>\n",
       "      <td>0.024521</td>\n",
       "      <td>0.038750</td>\n",
       "      <td>3.0</td>\n",
       "      <td>snare_38.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.015060</td>\n",
       "      <td>-21.076578</td>\n",
       "      <td>22.140637</td>\n",
       "      <td>0.103575</td>\n",
       "      <td>0.019697</td>\n",
       "      <td>0.017071</td>\n",
       "      <td>3.0</td>\n",
       "      <td>snare_39.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.021603</td>\n",
       "      <td>-20.621740</td>\n",
       "      <td>20.365652</td>\n",
       "      <td>0.131215</td>\n",
       "      <td>0.022071</td>\n",
       "      <td>0.027501</td>\n",
       "      <td>3.0</td>\n",
       "      <td>snare_40.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.036594</td>\n",
       "      <td>-20.375124</td>\n",
       "      <td>21.882323</td>\n",
       "      <td>0.172078</td>\n",
       "      <td>0.019771</td>\n",
       "      <td>0.028263</td>\n",
       "      <td>3.0</td>\n",
       "      <td>snare_41.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           sf       mfcc       scon       zcr       rms        tg  label  \\\n",
       "0    0.009266 -16.176497  20.150281  0.238694  0.042907  0.122623    0.0   \n",
       "1    0.060073 -15.045925  20.220686  0.181085  0.091807  0.012034    0.0   \n",
       "2    0.027080 -18.072697  20.386491  0.186275  0.060785  0.035546    0.0   \n",
       "3    0.053378 -29.048000  23.282097  0.261476  0.059042  0.148375    0.0   \n",
       "4    0.002444 -28.880560  21.106727  0.120479  0.012474  0.073228    0.0   \n",
       "..        ...        ...        ...       ...       ...       ...    ...   \n",
       "162  0.035142 -18.951557  21.133549  0.178874  0.022656  0.015246    3.0   \n",
       "163  0.022006 -19.046724  20.261291  0.146732  0.024521  0.038750    3.0   \n",
       "164  0.015060 -21.076578  22.140637  0.103575  0.019697  0.017071    3.0   \n",
       "165  0.021603 -20.621740  20.365652  0.131215  0.022071  0.027501    3.0   \n",
       "166  0.036594 -20.375124  21.882323  0.172078  0.019771  0.028263    3.0   \n",
       "\n",
       "         filename  \n",
       "0      clap00.wav  \n",
       "1      clap01.wav  \n",
       "2      clap02.wav  \n",
       "3      clap03.wav  \n",
       "4      clap04.wav  \n",
       "..            ...  \n",
       "162  snare_37.wav  \n",
       "163  snare_38.wav  \n",
       "164  snare_39.wav  \n",
       "165  snare_40.wav  \n",
       "166  snare_41.wav  \n",
       "\n",
       "[167 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the data\n",
    "dataset = pd.read_csv(r'dataset.csv' , index_col=0)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3121291",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset.label)\n",
    "features = np.array([dataset.sf, dataset.mfcc, dataset.scon, dataset.zcr, dataset.rms, dataset.tg]).T\n",
    "classes = ['clap','cymbal','kick','snare'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bbc7142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#splitting the dataset in training and testing parts\n",
    "feat_train, feat_test, lab_train, lab_test = train_test_split(features, labels, test_size=0.3, random_state=52)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a606f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning the scaling transformation from the train data and applying it to both train and test set.\n",
    "\n",
    "#creating scaling object\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "\n",
    "#learning scaling from train set\n",
    "scaler.fit(feat_train)\n",
    "\n",
    "#applying scaling to both train and test set\n",
    "feat_train = scaler.transform(feat_train)\n",
    "feat_test = scaler.transform(feat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514f4741",
   "metadata": {},
   "source": [
    "<h2 style = \"font-size:2rem;color:DarkCyan\"> Training the ANN </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a224da20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.62157670\n",
      "Iteration 2, loss = 1.61367638\n",
      "Iteration 3, loss = 1.60581703\n",
      "Iteration 4, loss = 1.59798609\n",
      "Iteration 5, loss = 1.59021026\n",
      "Iteration 6, loss = 1.58245864\n",
      "Iteration 7, loss = 1.57476047\n",
      "Iteration 8, loss = 1.56708964\n",
      "Iteration 9, loss = 1.55948580\n",
      "Iteration 10, loss = 1.55191891\n",
      "Iteration 11, loss = 1.54437617\n",
      "Iteration 12, loss = 1.53682257\n",
      "Iteration 13, loss = 1.52930714\n",
      "Iteration 14, loss = 1.52181784\n",
      "Iteration 15, loss = 1.51437659\n",
      "Iteration 16, loss = 1.50699257\n",
      "Iteration 17, loss = 1.49964799\n",
      "Iteration 18, loss = 1.49232462\n",
      "Iteration 19, loss = 1.48508341\n",
      "Iteration 20, loss = 1.47789978\n",
      "Iteration 21, loss = 1.47078092\n",
      "Iteration 22, loss = 1.46368606\n",
      "Iteration 23, loss = 1.45663257\n",
      "Iteration 24, loss = 1.44960013\n",
      "Iteration 25, loss = 1.44254083\n",
      "Iteration 26, loss = 1.43550382\n",
      "Iteration 27, loss = 1.42850436\n",
      "Iteration 28, loss = 1.42158613\n",
      "Iteration 29, loss = 1.41470856\n",
      "Iteration 30, loss = 1.40782710\n",
      "Iteration 31, loss = 1.40095876\n",
      "Iteration 32, loss = 1.39409898\n",
      "Iteration 33, loss = 1.38725845\n",
      "Iteration 34, loss = 1.38045222\n",
      "Iteration 35, loss = 1.37366113\n",
      "Iteration 36, loss = 1.36689049\n",
      "Iteration 37, loss = 1.36014877\n",
      "Iteration 38, loss = 1.35346660\n",
      "Iteration 39, loss = 1.34683709\n",
      "Iteration 40, loss = 1.34019373\n",
      "Iteration 41, loss = 1.33357267\n",
      "Iteration 42, loss = 1.32714460\n",
      "Iteration 43, loss = 1.32082912\n",
      "Iteration 44, loss = 1.31462177\n",
      "Iteration 45, loss = 1.30845494\n",
      "Iteration 46, loss = 1.30229196\n",
      "Iteration 47, loss = 1.29613747\n",
      "Iteration 48, loss = 1.28993635\n",
      "Iteration 49, loss = 1.28375300\n",
      "Iteration 50, loss = 1.27759391\n",
      "Iteration 51, loss = 1.27146661\n",
      "Iteration 52, loss = 1.26543347\n",
      "Iteration 53, loss = 1.25953370\n",
      "Iteration 54, loss = 1.25364552\n",
      "Iteration 55, loss = 1.24778530\n",
      "Iteration 56, loss = 1.24192064\n",
      "Iteration 57, loss = 1.23604825\n",
      "Iteration 58, loss = 1.23015654\n",
      "Iteration 59, loss = 1.22426880\n",
      "Iteration 60, loss = 1.21835931\n",
      "Iteration 61, loss = 1.21245157\n",
      "Iteration 62, loss = 1.20654100\n",
      "Iteration 63, loss = 1.20062662\n",
      "Iteration 64, loss = 1.19472164\n",
      "Iteration 65, loss = 1.18880534\n",
      "Iteration 66, loss = 1.18288647\n",
      "Iteration 67, loss = 1.17693647\n",
      "Iteration 68, loss = 1.17098823\n",
      "Iteration 69, loss = 1.16503371\n",
      "Iteration 70, loss = 1.15910359\n",
      "Iteration 71, loss = 1.15315834\n",
      "Iteration 72, loss = 1.14717833\n",
      "Iteration 73, loss = 1.14118064\n",
      "Iteration 74, loss = 1.13517986\n",
      "Iteration 75, loss = 1.12919444\n",
      "Iteration 76, loss = 1.12321158\n",
      "Iteration 77, loss = 1.11722510\n",
      "Iteration 78, loss = 1.11124425\n",
      "Iteration 79, loss = 1.10528716\n",
      "Iteration 80, loss = 1.09935561\n",
      "Iteration 81, loss = 1.09342340\n",
      "Iteration 82, loss = 1.08751387\n",
      "Iteration 83, loss = 1.08161610\n",
      "Iteration 84, loss = 1.07573852\n",
      "Iteration 85, loss = 1.06987936\n",
      "Iteration 86, loss = 1.06404431\n",
      "Iteration 87, loss = 1.05821039\n",
      "Iteration 88, loss = 1.05240142\n",
      "Iteration 89, loss = 1.04664172\n",
      "Iteration 90, loss = 1.04090718\n",
      "Iteration 91, loss = 1.03518879\n",
      "Iteration 92, loss = 1.02949273\n",
      "Iteration 93, loss = 1.02383044\n",
      "Iteration 94, loss = 1.01823007\n",
      "Iteration 95, loss = 1.01269230\n",
      "Iteration 96, loss = 1.00721114\n",
      "Iteration 97, loss = 1.00177557\n",
      "Iteration 98, loss = 0.99636040\n",
      "Iteration 99, loss = 0.99094196\n",
      "Iteration 100, loss = 0.98558616\n",
      "Iteration 101, loss = 0.98028074\n",
      "Iteration 102, loss = 0.97502327\n",
      "Iteration 103, loss = 0.96982644\n",
      "Iteration 104, loss = 0.96468276\n",
      "Iteration 105, loss = 0.95957526\n",
      "Iteration 106, loss = 0.95446699\n",
      "Iteration 107, loss = 0.94933035\n",
      "Iteration 108, loss = 0.94419766\n",
      "Iteration 109, loss = 0.93905500\n",
      "Iteration 110, loss = 0.93396075\n",
      "Iteration 111, loss = 0.92892116\n",
      "Iteration 112, loss = 0.92393065\n",
      "Iteration 113, loss = 0.91897477\n",
      "Iteration 114, loss = 0.91404579\n",
      "Iteration 115, loss = 0.90916129\n",
      "Iteration 116, loss = 0.90428736\n",
      "Iteration 117, loss = 0.89945791\n",
      "Iteration 118, loss = 0.89467777\n",
      "Iteration 119, loss = 0.88994332\n",
      "Iteration 120, loss = 0.88526808\n",
      "Iteration 121, loss = 0.88065408\n",
      "Iteration 122, loss = 0.87609969\n",
      "Iteration 123, loss = 0.87159185\n",
      "Iteration 124, loss = 0.86712548\n",
      "Iteration 125, loss = 0.86271547\n",
      "Iteration 126, loss = 0.85835080\n",
      "Iteration 127, loss = 0.85402860\n",
      "Iteration 128, loss = 0.84976019\n",
      "Iteration 129, loss = 0.84556043\n",
      "Iteration 130, loss = 0.84141953\n",
      "Iteration 131, loss = 0.83732493\n",
      "Iteration 132, loss = 0.83327838\n",
      "Iteration 133, loss = 0.82927680\n",
      "Iteration 134, loss = 0.82532010\n",
      "Iteration 135, loss = 0.82141020\n",
      "Iteration 136, loss = 0.81754358\n",
      "Iteration 137, loss = 0.81372041\n",
      "Iteration 138, loss = 0.80993965\n",
      "Iteration 139, loss = 0.80620647\n",
      "Iteration 140, loss = 0.80249075\n",
      "Iteration 141, loss = 0.79880781\n",
      "Iteration 142, loss = 0.79516417\n",
      "Iteration 143, loss = 0.79156449\n",
      "Iteration 144, loss = 0.78800107\n",
      "Iteration 145, loss = 0.78445607\n",
      "Iteration 146, loss = 0.78096367\n",
      "Iteration 147, loss = 0.77750597\n",
      "Iteration 148, loss = 0.77404452\n",
      "Iteration 149, loss = 0.77059005\n",
      "Iteration 150, loss = 0.76715775\n",
      "Iteration 151, loss = 0.76375325\n",
      "Iteration 152, loss = 0.76039972\n",
      "Iteration 153, loss = 0.75707667\n",
      "Iteration 154, loss = 0.75377404\n",
      "Iteration 155, loss = 0.75049783\n",
      "Iteration 156, loss = 0.74724271\n",
      "Iteration 157, loss = 0.74400836\n",
      "Iteration 158, loss = 0.74079575\n",
      "Iteration 159, loss = 0.73760366\n",
      "Iteration 160, loss = 0.73441782\n",
      "Iteration 161, loss = 0.73124763\n",
      "Iteration 162, loss = 0.72806403\n",
      "Iteration 163, loss = 0.72489485\n",
      "Iteration 164, loss = 0.72174042\n",
      "Iteration 165, loss = 0.71859875\n",
      "Iteration 166, loss = 0.71547232\n",
      "Iteration 167, loss = 0.71238370\n",
      "Iteration 168, loss = 0.70932223\n",
      "Iteration 169, loss = 0.70628210\n",
      "Iteration 170, loss = 0.70324319\n",
      "Iteration 171, loss = 0.70020643\n",
      "Iteration 172, loss = 0.69719362\n",
      "Iteration 173, loss = 0.69420344\n",
      "Iteration 174, loss = 0.69123339\n",
      "Iteration 175, loss = 0.68828470\n",
      "Iteration 176, loss = 0.68534860\n",
      "Iteration 177, loss = 0.68241980\n",
      "Iteration 178, loss = 0.67948477\n",
      "Iteration 179, loss = 0.67655069\n",
      "Iteration 180, loss = 0.67362579\n",
      "Iteration 181, loss = 0.67071258\n",
      "Iteration 182, loss = 0.66780181\n",
      "Iteration 183, loss = 0.66489789\n",
      "Iteration 184, loss = 0.66199210\n",
      "Iteration 185, loss = 0.65909657\n",
      "Iteration 186, loss = 0.65621180\n",
      "Iteration 187, loss = 0.65333446\n",
      "Iteration 188, loss = 0.65045777\n",
      "Iteration 189, loss = 0.64758247\n",
      "Iteration 190, loss = 0.64471278\n",
      "Iteration 191, loss = 0.64184465\n",
      "Iteration 192, loss = 0.63895255\n",
      "Iteration 193, loss = 0.63608287\n",
      "Iteration 194, loss = 0.63321729\n",
      "Iteration 195, loss = 0.63037647\n",
      "Iteration 196, loss = 0.62753092\n",
      "Iteration 197, loss = 0.62467976\n",
      "Iteration 198, loss = 0.62182495\n",
      "Iteration 199, loss = 0.61896033\n",
      "Iteration 200, loss = 0.61608269\n",
      "Iteration 201, loss = 0.61321331\n",
      "Iteration 202, loss = 0.61033100\n",
      "Iteration 203, loss = 0.60744137\n",
      "Iteration 204, loss = 0.60455878\n",
      "Iteration 205, loss = 0.60167123\n",
      "Iteration 206, loss = 0.59878031\n",
      "Iteration 207, loss = 0.59587908\n",
      "Iteration 208, loss = 0.59294394\n",
      "Iteration 209, loss = 0.59000577\n",
      "Iteration 210, loss = 0.58706758\n",
      "Iteration 211, loss = 0.58414571\n",
      "Iteration 212, loss = 0.58122870\n",
      "Iteration 213, loss = 0.57830326\n",
      "Iteration 214, loss = 0.57534669\n",
      "Iteration 215, loss = 0.57239002\n",
      "Iteration 216, loss = 0.56944360\n",
      "Iteration 217, loss = 0.56650401\n",
      "Iteration 218, loss = 0.56353421\n",
      "Iteration 219, loss = 0.56054031\n",
      "Iteration 220, loss = 0.55754485\n",
      "Iteration 221, loss = 0.55455335\n",
      "Iteration 222, loss = 0.55156287\n",
      "Iteration 223, loss = 0.54857665\n",
      "Iteration 224, loss = 0.54559466\n",
      "Iteration 225, loss = 0.54261816\n",
      "Iteration 226, loss = 0.53965686\n",
      "Iteration 227, loss = 0.53672055\n",
      "Iteration 228, loss = 0.53379085\n",
      "Iteration 229, loss = 0.53087387\n",
      "Iteration 230, loss = 0.52796625\n",
      "Iteration 231, loss = 0.52506672\n",
      "Iteration 232, loss = 0.52218180\n",
      "Iteration 233, loss = 0.51930880\n",
      "Iteration 234, loss = 0.51644902\n",
      "Iteration 235, loss = 0.51360621\n",
      "Iteration 236, loss = 0.51078142\n",
      "Iteration 237, loss = 0.50797426\n",
      "Iteration 238, loss = 0.50518091\n",
      "Iteration 239, loss = 0.50240070\n",
      "Iteration 240, loss = 0.49963161\n",
      "Iteration 241, loss = 0.49687546\n",
      "Iteration 242, loss = 0.49413139\n",
      "Iteration 243, loss = 0.49140928\n",
      "Iteration 244, loss = 0.48870389\n",
      "Iteration 245, loss = 0.48601028\n",
      "Iteration 246, loss = 0.48333421\n",
      "Iteration 247, loss = 0.48067673\n",
      "Iteration 248, loss = 0.47804004\n",
      "Iteration 249, loss = 0.47541158\n",
      "Iteration 250, loss = 0.47279902\n",
      "Iteration 251, loss = 0.47020942\n",
      "Iteration 252, loss = 0.46764333\n",
      "Iteration 253, loss = 0.46509806\n",
      "Iteration 254, loss = 0.46257194\n",
      "Iteration 255, loss = 0.46007345\n",
      "Iteration 256, loss = 0.45759539\n",
      "Iteration 257, loss = 0.45513295\n",
      "Iteration 258, loss = 0.45269186\n",
      "Iteration 259, loss = 0.45030363\n",
      "Iteration 260, loss = 0.44797158\n",
      "Iteration 261, loss = 0.44566334\n",
      "Iteration 262, loss = 0.44338848\n",
      "Iteration 263, loss = 0.44113716\n",
      "Iteration 264, loss = 0.43890981\n",
      "Iteration 265, loss = 0.43670200\n",
      "Iteration 266, loss = 0.43451380\n",
      "Iteration 267, loss = 0.43236385\n",
      "Iteration 268, loss = 0.43025471\n",
      "Iteration 269, loss = 0.42816649\n",
      "Iteration 270, loss = 0.42610018\n",
      "Iteration 271, loss = 0.42405038\n",
      "Iteration 272, loss = 0.42202011\n",
      "Iteration 273, loss = 0.42001013\n",
      "Iteration 274, loss = 0.41801906\n",
      "Iteration 275, loss = 0.41604553\n",
      "Iteration 276, loss = 0.41409175\n",
      "Iteration 277, loss = 0.41216245\n",
      "Iteration 278, loss = 0.41025057\n",
      "Iteration 279, loss = 0.40836413\n",
      "Iteration 280, loss = 0.40651076\n",
      "Iteration 281, loss = 0.40467598\n",
      "Iteration 282, loss = 0.40287308\n",
      "Iteration 283, loss = 0.40109204\n",
      "Iteration 284, loss = 0.39932533\n",
      "Iteration 285, loss = 0.39757696\n",
      "Iteration 286, loss = 0.39584419\n",
      "Iteration 287, loss = 0.39412694\n",
      "Iteration 288, loss = 0.39242391\n",
      "Iteration 289, loss = 0.39073351\n",
      "Iteration 290, loss = 0.38905801\n",
      "Iteration 291, loss = 0.38740263\n",
      "Iteration 292, loss = 0.38576549\n",
      "Iteration 293, loss = 0.38413740\n",
      "Iteration 294, loss = 0.38252396\n",
      "Iteration 295, loss = 0.38092591\n",
      "Iteration 296, loss = 0.37934509\n",
      "Iteration 297, loss = 0.37778923\n",
      "Iteration 298, loss = 0.37624738\n",
      "Iteration 299, loss = 0.37471632\n",
      "Iteration 300, loss = 0.37319670\n",
      "Iteration 301, loss = 0.37168755\n",
      "Iteration 302, loss = 0.37018853\n",
      "Iteration 303, loss = 0.36870193\n",
      "Iteration 304, loss = 0.36722597\n",
      "Iteration 305, loss = 0.36575950\n",
      "Iteration 306, loss = 0.36431061\n",
      "Iteration 307, loss = 0.36288355\n",
      "Iteration 308, loss = 0.36146594\n",
      "Iteration 309, loss = 0.36005943\n",
      "Iteration 310, loss = 0.35866108\n",
      "Iteration 311, loss = 0.35728014\n",
      "Iteration 312, loss = 0.35591096\n",
      "Iteration 313, loss = 0.35455123\n",
      "Iteration 314, loss = 0.35320498\n",
      "Iteration 315, loss = 0.35187060\n",
      "Iteration 316, loss = 0.35054385\n",
      "Iteration 317, loss = 0.34922910\n",
      "Iteration 318, loss = 0.34793197\n",
      "Iteration 319, loss = 0.34664098\n",
      "Iteration 320, loss = 0.34537049\n",
      "Iteration 321, loss = 0.34411628\n",
      "Iteration 322, loss = 0.34287616\n",
      "Iteration 323, loss = 0.34163949\n",
      "Iteration 324, loss = 0.34040443\n",
      "Iteration 325, loss = 0.33917752\n",
      "Iteration 326, loss = 0.33797361\n",
      "Iteration 327, loss = 0.33677422\n",
      "Iteration 328, loss = 0.33557982\n",
      "Iteration 329, loss = 0.33440048\n",
      "Iteration 330, loss = 0.33322487\n",
      "Iteration 331, loss = 0.33205398\n",
      "Iteration 332, loss = 0.33089469\n",
      "Iteration 333, loss = 0.32974566\n",
      "Iteration 334, loss = 0.32860386\n",
      "Iteration 335, loss = 0.32746707\n",
      "Iteration 336, loss = 0.32633879\n",
      "Iteration 337, loss = 0.32522507\n",
      "Iteration 338, loss = 0.32411197\n",
      "Iteration 339, loss = 0.32300564\n",
      "Iteration 340, loss = 0.32191258\n",
      "Iteration 341, loss = 0.32082563\n",
      "Iteration 342, loss = 0.31973887\n",
      "Iteration 343, loss = 0.31866483\n",
      "Iteration 344, loss = 0.31759580\n",
      "Iteration 345, loss = 0.31653074\n",
      "Iteration 346, loss = 0.31547015\n",
      "Iteration 347, loss = 0.31442079\n",
      "Iteration 348, loss = 0.31337728\n",
      "Iteration 349, loss = 0.31233655\n",
      "Iteration 350, loss = 0.31130022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 351, loss = 0.31027009\n",
      "Iteration 352, loss = 0.30924394\n",
      "Iteration 353, loss = 0.30822157\n",
      "Iteration 354, loss = 0.30721280\n",
      "Iteration 355, loss = 0.30620831\n",
      "Iteration 356, loss = 0.30520804\n",
      "Iteration 357, loss = 0.30421473\n",
      "Iteration 358, loss = 0.30321359\n",
      "Iteration 359, loss = 0.30220461\n",
      "Iteration 360, loss = 0.30117065\n",
      "Iteration 361, loss = 0.30013013\n",
      "Iteration 362, loss = 0.29908325\n",
      "Iteration 363, loss = 0.29807817\n",
      "Iteration 364, loss = 0.29708550\n",
      "Iteration 365, loss = 0.29606776\n",
      "Iteration 366, loss = 0.29502321\n",
      "Iteration 367, loss = 0.29396022\n",
      "Iteration 368, loss = 0.29286522\n",
      "Iteration 369, loss = 0.29174932\n",
      "Iteration 370, loss = 0.29070129\n",
      "Iteration 371, loss = 0.28970113\n",
      "Iteration 372, loss = 0.28870590\n",
      "Iteration 373, loss = 0.28771324\n",
      "Iteration 374, loss = 0.28671668\n",
      "Iteration 375, loss = 0.28571759\n",
      "Iteration 376, loss = 0.28471126\n",
      "Iteration 377, loss = 0.28370445\n",
      "Iteration 378, loss = 0.28270060\n",
      "Iteration 379, loss = 0.28169642\n",
      "Iteration 380, loss = 0.28068899\n",
      "Iteration 381, loss = 0.27968341\n",
      "Iteration 382, loss = 0.27867983\n",
      "Iteration 383, loss = 0.27769725\n",
      "Iteration 384, loss = 0.27672096\n",
      "Iteration 385, loss = 0.27575316\n",
      "Iteration 386, loss = 0.27479231\n",
      "Iteration 387, loss = 0.27383761\n",
      "Iteration 388, loss = 0.27288626\n",
      "Iteration 389, loss = 0.27194386\n",
      "Iteration 390, loss = 0.27102870\n",
      "Iteration 391, loss = 0.27011880\n",
      "Iteration 392, loss = 0.26920816\n",
      "Iteration 393, loss = 0.26830558\n",
      "Iteration 394, loss = 0.26740634\n",
      "Iteration 395, loss = 0.26651287\n",
      "Iteration 396, loss = 0.26562084\n",
      "Iteration 397, loss = 0.26473408\n",
      "Iteration 398, loss = 0.26385527\n",
      "Iteration 399, loss = 0.26298062\n",
      "Iteration 400, loss = 0.26210419\n",
      "Iteration 401, loss = 0.26123413\n",
      "Iteration 402, loss = 0.26036555\n",
      "Iteration 403, loss = 0.25949961\n",
      "Iteration 404, loss = 0.25863415\n",
      "Iteration 405, loss = 0.25777808\n",
      "Iteration 406, loss = 0.25693233\n",
      "Iteration 407, loss = 0.25608636\n",
      "Iteration 408, loss = 0.25524804\n",
      "Iteration 409, loss = 0.25441005\n",
      "Iteration 410, loss = 0.25357495\n",
      "Iteration 411, loss = 0.25273996\n",
      "Iteration 412, loss = 0.25191210\n",
      "Iteration 413, loss = 0.25109514\n",
      "Iteration 414, loss = 0.25028300\n",
      "Iteration 415, loss = 0.24947401\n",
      "Iteration 416, loss = 0.24866177\n",
      "Iteration 417, loss = 0.24785704\n",
      "Iteration 418, loss = 0.24705304\n",
      "Iteration 419, loss = 0.24625483\n",
      "Iteration 420, loss = 0.24545918\n",
      "Iteration 421, loss = 0.24466626\n",
      "Iteration 422, loss = 0.24387755\n",
      "Iteration 423, loss = 0.24309046\n",
      "Iteration 424, loss = 0.24230668\n",
      "Iteration 425, loss = 0.24153306\n",
      "Iteration 426, loss = 0.24076382\n",
      "Iteration 427, loss = 0.23999706\n",
      "Iteration 428, loss = 0.23923024\n",
      "Iteration 429, loss = 0.23846987\n",
      "Iteration 430, loss = 0.23771424\n",
      "Iteration 431, loss = 0.23696293\n",
      "Iteration 432, loss = 0.23621444\n",
      "Iteration 433, loss = 0.23546941\n",
      "Iteration 434, loss = 0.23472703\n",
      "Iteration 435, loss = 0.23400309\n",
      "Iteration 436, loss = 0.23328810\n",
      "Iteration 437, loss = 0.23257095\n",
      "Iteration 438, loss = 0.23185194\n",
      "Iteration 439, loss = 0.23113551\n",
      "Iteration 440, loss = 0.23042074\n",
      "Iteration 441, loss = 0.22970045\n",
      "Iteration 442, loss = 0.22898429\n",
      "Iteration 443, loss = 0.22828421\n",
      "Iteration 444, loss = 0.22759481\n",
      "Iteration 445, loss = 0.22690115\n",
      "Iteration 446, loss = 0.22620900\n",
      "Iteration 447, loss = 0.22552471\n",
      "Iteration 448, loss = 0.22483606\n",
      "Iteration 449, loss = 0.22415946\n",
      "Iteration 450, loss = 0.22348788\n",
      "Iteration 451, loss = 0.22281309\n",
      "Iteration 452, loss = 0.22214769\n",
      "Iteration 453, loss = 0.22149370\n",
      "Iteration 454, loss = 0.22083179\n",
      "Iteration 455, loss = 0.22017633\n",
      "Iteration 456, loss = 0.21952620\n",
      "Iteration 457, loss = 0.21887863\n",
      "Iteration 458, loss = 0.21822250\n",
      "Iteration 459, loss = 0.21756942\n",
      "Iteration 460, loss = 0.21691736\n",
      "Iteration 461, loss = 0.21626783\n",
      "Iteration 462, loss = 0.21562946\n",
      "Iteration 463, loss = 0.21498782\n",
      "Iteration 464, loss = 0.21434764\n",
      "Iteration 465, loss = 0.21371471\n",
      "Iteration 466, loss = 0.21308149\n",
      "Iteration 467, loss = 0.21245014\n",
      "Iteration 468, loss = 0.21181816\n",
      "Iteration 469, loss = 0.21119601\n",
      "Iteration 470, loss = 0.21057362\n",
      "Iteration 471, loss = 0.20995273\n",
      "Iteration 472, loss = 0.20933823\n",
      "Iteration 473, loss = 0.20872224\n",
      "Iteration 474, loss = 0.20810467\n",
      "Iteration 475, loss = 0.20749339\n",
      "Iteration 476, loss = 0.20688566\n",
      "Iteration 477, loss = 0.20628399\n",
      "Iteration 478, loss = 0.20568051\n",
      "Iteration 479, loss = 0.20507741\n",
      "Iteration 480, loss = 0.20448248\n",
      "Iteration 481, loss = 0.20388650\n",
      "Iteration 482, loss = 0.20328901\n",
      "Iteration 483, loss = 0.20270242\n",
      "Iteration 484, loss = 0.20211543\n",
      "Iteration 485, loss = 0.20152528\n",
      "Iteration 486, loss = 0.20093740\n",
      "Iteration 487, loss = 0.20035951\n",
      "Iteration 488, loss = 0.19978072\n",
      "Iteration 489, loss = 0.19920125\n",
      "Iteration 490, loss = 0.19862829\n",
      "Iteration 491, loss = 0.19805432\n",
      "Iteration 492, loss = 0.19748556\n",
      "Iteration 493, loss = 0.19691429\n",
      "Iteration 494, loss = 0.19634968\n",
      "Iteration 495, loss = 0.19578686\n",
      "Iteration 496, loss = 0.19522039\n",
      "Iteration 497, loss = 0.19466490\n",
      "Iteration 498, loss = 0.19410570\n",
      "Iteration 499, loss = 0.19354301\n",
      "Iteration 500, loss = 0.19298200\n",
      "Iteration 501, loss = 0.19242493\n",
      "Iteration 502, loss = 0.19186915\n",
      "Iteration 503, loss = 0.19131355\n",
      "Iteration 504, loss = 0.19075776\n",
      "Iteration 505, loss = 0.19020714\n",
      "Iteration 506, loss = 0.18965672\n",
      "Iteration 507, loss = 0.18910900\n",
      "Iteration 508, loss = 0.18856246\n",
      "Iteration 509, loss = 0.18801206\n",
      "Iteration 510, loss = 0.18746940\n",
      "Iteration 511, loss = 0.18692345\n",
      "Iteration 512, loss = 0.18637689\n",
      "Iteration 513, loss = 0.18583235\n",
      "Iteration 514, loss = 0.18529350\n",
      "Iteration 515, loss = 0.18475259\n",
      "Iteration 516, loss = 0.18421460\n",
      "Iteration 517, loss = 0.18367898\n",
      "Iteration 518, loss = 0.18314130\n",
      "Iteration 519, loss = 0.18260240\n",
      "Iteration 520, loss = 0.18206970\n",
      "Iteration 521, loss = 0.18154174\n",
      "Iteration 522, loss = 0.18100968\n",
      "Iteration 523, loss = 0.18047809\n",
      "Iteration 524, loss = 0.17995506\n",
      "Iteration 525, loss = 0.17943457\n",
      "Iteration 526, loss = 0.17891298\n",
      "Iteration 527, loss = 0.17838827\n",
      "Iteration 528, loss = 0.17786381\n",
      "Iteration 529, loss = 0.17734233\n",
      "Iteration 530, loss = 0.17682163\n",
      "Iteration 531, loss = 0.17629969\n",
      "Iteration 532, loss = 0.17578061\n",
      "Iteration 533, loss = 0.17526449\n",
      "Iteration 534, loss = 0.17474799\n",
      "Iteration 535, loss = 0.17423337\n",
      "Iteration 536, loss = 0.17372523\n",
      "Iteration 537, loss = 0.17323110\n",
      "Iteration 538, loss = 0.17274559\n",
      "Iteration 539, loss = 0.17225937\n",
      "Iteration 540, loss = 0.17177399\n",
      "Iteration 541, loss = 0.17129019\n",
      "Iteration 542, loss = 0.17081043\n",
      "Iteration 543, loss = 0.17032951\n",
      "Iteration 544, loss = 0.16984530\n",
      "Iteration 545, loss = 0.16936626\n",
      "Iteration 546, loss = 0.16888641\n",
      "Iteration 547, loss = 0.16840823\n",
      "Iteration 548, loss = 0.16793478\n",
      "Iteration 549, loss = 0.16745990\n",
      "Iteration 550, loss = 0.16698281\n",
      "Iteration 551, loss = 0.16651249\n",
      "Iteration 552, loss = 0.16604559\n",
      "Iteration 553, loss = 0.16558241\n",
      "Iteration 554, loss = 0.16511492\n",
      "Iteration 555, loss = 0.16465423\n",
      "Iteration 556, loss = 0.16419443\n",
      "Iteration 557, loss = 0.16373215\n",
      "Iteration 558, loss = 0.16327458\n",
      "Iteration 559, loss = 0.16281678\n",
      "Iteration 560, loss = 0.16236063\n",
      "Iteration 561, loss = 0.16190998\n",
      "Iteration 562, loss = 0.16146336\n",
      "Iteration 563, loss = 0.16101149\n",
      "Iteration 564, loss = 0.16056300\n",
      "Iteration 565, loss = 0.16011933\n",
      "Iteration 566, loss = 0.15967701\n",
      "Iteration 567, loss = 0.15923711\n",
      "Iteration 568, loss = 0.15879477\n",
      "Iteration 569, loss = 0.15835665\n",
      "Iteration 570, loss = 0.15792043\n",
      "Iteration 571, loss = 0.15748579\n",
      "Iteration 572, loss = 0.15705479\n",
      "Iteration 573, loss = 0.15662573\n",
      "Iteration 574, loss = 0.15619686\n",
      "Iteration 575, loss = 0.15577426\n",
      "Iteration 576, loss = 0.15535148\n",
      "Iteration 577, loss = 0.15492597\n",
      "Iteration 578, loss = 0.15450776\n",
      "Iteration 579, loss = 0.15409484\n",
      "Iteration 580, loss = 0.15367835\n",
      "Iteration 581, loss = 0.15325940\n",
      "Iteration 582, loss = 0.15284118\n",
      "Iteration 583, loss = 0.15243604\n",
      "Iteration 584, loss = 0.15202865\n",
      "Iteration 585, loss = 0.15161481\n",
      "Iteration 586, loss = 0.15120796\n",
      "Iteration 587, loss = 0.15080762\n",
      "Iteration 588, loss = 0.15040583\n",
      "Iteration 589, loss = 0.15000347\n",
      "Iteration 590, loss = 0.14960245\n",
      "Iteration 591, loss = 0.14920033\n",
      "Iteration 592, loss = 0.14880005\n",
      "Iteration 593, loss = 0.14841014\n",
      "Iteration 594, loss = 0.14801977\n",
      "Iteration 595, loss = 0.14762241\n",
      "Iteration 596, loss = 0.14723118\n",
      "Iteration 597, loss = 0.14684797\n",
      "Iteration 598, loss = 0.14646209\n",
      "Iteration 599, loss = 0.14607639\n",
      "Iteration 600, loss = 0.14568924\n",
      "Iteration 601, loss = 0.14530398\n",
      "Iteration 602, loss = 0.14492184\n",
      "Iteration 603, loss = 0.14454044\n",
      "Iteration 604, loss = 0.14416202\n",
      "Iteration 605, loss = 0.14378355\n",
      "Iteration 606, loss = 0.14340620\n",
      "Iteration 607, loss = 0.14303056\n",
      "Iteration 608, loss = 0.14265670\n",
      "Iteration 609, loss = 0.14228289\n",
      "Iteration 610, loss = 0.14191059\n",
      "Iteration 611, loss = 0.14154209\n",
      "Iteration 612, loss = 0.14117459\n",
      "Iteration 613, loss = 0.14081395\n",
      "Iteration 614, loss = 0.14045270\n",
      "Iteration 615, loss = 0.14008548\n",
      "Iteration 616, loss = 0.13971936\n",
      "Iteration 617, loss = 0.13936067\n",
      "Iteration 618, loss = 0.13900202\n",
      "Iteration 619, loss = 0.13864435\n",
      "Iteration 620, loss = 0.13828967\n",
      "Iteration 621, loss = 0.13793351\n",
      "Iteration 622, loss = 0.13757811\n",
      "Iteration 623, loss = 0.13722353\n",
      "Iteration 624, loss = 0.13687516\n",
      "Iteration 625, loss = 0.13652273\n",
      "Iteration 626, loss = 0.13617600\n",
      "Iteration 627, loss = 0.13582760\n",
      "Iteration 628, loss = 0.13547692\n",
      "Iteration 629, loss = 0.13512730\n",
      "Iteration 630, loss = 0.13478823\n",
      "Iteration 631, loss = 0.13444282\n",
      "Iteration 632, loss = 0.13409745\n",
      "Iteration 633, loss = 0.13375564\n",
      "Iteration 634, loss = 0.13341522\n",
      "Iteration 635, loss = 0.13307708\n",
      "Iteration 636, loss = 0.13273685\n",
      "Iteration 637, loss = 0.13239912\n",
      "Iteration 638, loss = 0.13206179\n",
      "Iteration 639, loss = 0.13172363\n",
      "Iteration 640, loss = 0.13138986\n",
      "Iteration 641, loss = 0.13105829\n",
      "Iteration 642, loss = 0.13072771\n",
      "Iteration 643, loss = 0.13039524\n",
      "Iteration 644, loss = 0.13006504\n",
      "Iteration 645, loss = 0.12973566\n",
      "Iteration 646, loss = 0.12940827\n",
      "Iteration 647, loss = 0.12908251\n",
      "Iteration 648, loss = 0.12875736\n",
      "Iteration 649, loss = 0.12843447\n",
      "Iteration 650, loss = 0.12811475\n",
      "Iteration 651, loss = 0.12779216\n",
      "Iteration 652, loss = 0.12747198\n",
      "Iteration 653, loss = 0.12715434\n",
      "Iteration 654, loss = 0.12683902\n",
      "Iteration 655, loss = 0.12652441\n",
      "Iteration 656, loss = 0.12620936\n",
      "Iteration 657, loss = 0.12589482\n",
      "Iteration 658, loss = 0.12558178\n",
      "Iteration 659, loss = 0.12527386\n",
      "Iteration 660, loss = 0.12496327\n",
      "Iteration 661, loss = 0.12465024\n",
      "Iteration 662, loss = 0.12434123\n",
      "Iteration 663, loss = 0.12403607\n",
      "Iteration 664, loss = 0.12373020\n",
      "Iteration 665, loss = 0.12342839\n",
      "Iteration 666, loss = 0.12312498\n",
      "Iteration 667, loss = 0.12281797\n",
      "Iteration 668, loss = 0.12252218\n",
      "Iteration 669, loss = 0.12221922\n",
      "Iteration 670, loss = 0.12191808\n",
      "Iteration 671, loss = 0.12162310\n",
      "Iteration 672, loss = 0.12132223\n",
      "Iteration 673, loss = 0.12102595\n",
      "Iteration 674, loss = 0.12072849\n",
      "Iteration 675, loss = 0.12043067\n",
      "Iteration 676, loss = 0.12013197\n",
      "Iteration 677, loss = 0.11983758\n",
      "Iteration 678, loss = 0.11954882\n",
      "Iteration 679, loss = 0.11925207\n",
      "Iteration 680, loss = 0.11895911\n",
      "Iteration 681, loss = 0.11867222\n",
      "Iteration 682, loss = 0.11837987\n",
      "Iteration 683, loss = 0.11809002\n",
      "Iteration 684, loss = 0.11780084\n",
      "Iteration 685, loss = 0.11751342\n",
      "Iteration 686, loss = 0.11722612\n",
      "Iteration 687, loss = 0.11693954\n",
      "Iteration 688, loss = 0.11665334\n",
      "Iteration 689, loss = 0.11637058\n",
      "Iteration 690, loss = 0.11608735\n",
      "Iteration 691, loss = 0.11580570\n",
      "Iteration 692, loss = 0.11552349\n",
      "Iteration 693, loss = 0.11524209\n",
      "Iteration 694, loss = 0.11496076\n",
      "Iteration 695, loss = 0.11468224\n",
      "Iteration 696, loss = 0.11440661\n",
      "Iteration 697, loss = 0.11412636\n",
      "Iteration 698, loss = 0.11385135\n",
      "Iteration 699, loss = 0.11357474\n",
      "Iteration 700, loss = 0.11330045\n",
      "Iteration 701, loss = 0.11303081\n",
      "Iteration 702, loss = 0.11275418\n",
      "Iteration 703, loss = 0.11248227\n",
      "Iteration 704, loss = 0.11221129\n",
      "Iteration 705, loss = 0.11194071\n",
      "Iteration 706, loss = 0.11167409\n",
      "Iteration 707, loss = 0.11140147\n",
      "Iteration 708, loss = 0.11113196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 709, loss = 0.11086461\n",
      "Iteration 710, loss = 0.11060075\n",
      "Iteration 711, loss = 0.11033228\n",
      "Iteration 712, loss = 0.11006894\n",
      "Iteration 713, loss = 0.10980684\n",
      "Iteration 714, loss = 0.10954400\n",
      "Iteration 715, loss = 0.10928102\n",
      "Iteration 716, loss = 0.10902122\n",
      "Iteration 717, loss = 0.10875927\n",
      "Iteration 718, loss = 0.10850096\n",
      "Iteration 719, loss = 0.10824270\n",
      "Iteration 720, loss = 0.10798377\n",
      "Iteration 721, loss = 0.10773137\n",
      "Iteration 722, loss = 0.10747628\n",
      "Iteration 723, loss = 0.10721812\n",
      "Iteration 724, loss = 0.10696733\n",
      "Iteration 725, loss = 0.10671481\n",
      "Iteration 726, loss = 0.10646314\n",
      "Iteration 727, loss = 0.10621224\n",
      "Iteration 728, loss = 0.10596110\n",
      "Iteration 729, loss = 0.10571553\n",
      "Iteration 730, loss = 0.10546220\n",
      "Iteration 731, loss = 0.10521966\n",
      "Iteration 732, loss = 0.10498062\n",
      "Iteration 733, loss = 0.10474476\n",
      "Iteration 734, loss = 0.10451150\n",
      "Iteration 735, loss = 0.10427507\n",
      "Iteration 736, loss = 0.10403622\n",
      "Iteration 737, loss = 0.10379684\n",
      "Iteration 738, loss = 0.10356038\n",
      "Iteration 739, loss = 0.10332339\n",
      "Iteration 740, loss = 0.10308893\n",
      "Iteration 741, loss = 0.10285512\n",
      "Iteration 742, loss = 0.10262063\n",
      "Iteration 743, loss = 0.10238980\n",
      "Iteration 744, loss = 0.10215977\n",
      "Iteration 745, loss = 0.10192937\n",
      "Iteration 746, loss = 0.10169575\n",
      "Iteration 747, loss = 0.10146605\n",
      "Iteration 748, loss = 0.10124566\n",
      "Iteration 749, loss = 0.10102669\n",
      "Iteration 750, loss = 0.10080262\n",
      "Iteration 751, loss = 0.10057374\n",
      "Iteration 752, loss = 0.10034734\n",
      "Iteration 753, loss = 0.10011933\n",
      "Iteration 754, loss = 0.09988904\n",
      "Iteration 755, loss = 0.09966051\n",
      "Iteration 756, loss = 0.09946443\n",
      "Iteration 757, loss = 0.09920987\n",
      "Iteration 758, loss = 0.09899482\n",
      "Iteration 759, loss = 0.09877861\n",
      "Iteration 760, loss = 0.09858342\n",
      "Iteration 761, loss = 0.09834953\n",
      "Iteration 762, loss = 0.09813301\n",
      "Iteration 763, loss = 0.09791832\n",
      "Iteration 764, loss = 0.09772075\n",
      "Iteration 765, loss = 0.09751061\n",
      "Iteration 766, loss = 0.09729518\n",
      "Iteration 767, loss = 0.09707460\n",
      "Iteration 768, loss = 0.09691438\n",
      "Iteration 769, loss = 0.09669478\n",
      "Iteration 770, loss = 0.09645485\n",
      "Iteration 771, loss = 0.09626349\n",
      "Iteration 772, loss = 0.09605791\n",
      "Iteration 773, loss = 0.09584605\n",
      "Iteration 774, loss = 0.09562562\n",
      "Iteration 775, loss = 0.09547461\n",
      "Iteration 776, loss = 0.09527400\n",
      "Iteration 777, loss = 0.09501731\n",
      "Iteration 778, loss = 0.09485338\n",
      "Iteration 779, loss = 0.09468333\n",
      "Iteration 780, loss = 0.09449939\n",
      "Iteration 781, loss = 0.09430444\n",
      "Iteration 782, loss = 0.09410578\n",
      "Iteration 783, loss = 0.09389788\n",
      "Iteration 784, loss = 0.09367945\n",
      "Iteration 785, loss = 0.09345622\n",
      "Iteration 786, loss = 0.09328104\n",
      "Iteration 787, loss = 0.09310971\n",
      "Iteration 788, loss = 0.09288361\n",
      "Iteration 789, loss = 0.09270394\n",
      "Iteration 790, loss = 0.09254041\n",
      "Iteration 791, loss = 0.09236464\n",
      "Iteration 792, loss = 0.09217569\n",
      "Iteration 793, loss = 0.09197293\n",
      "Iteration 794, loss = 0.09176272\n",
      "Iteration 795, loss = 0.09162285\n",
      "Iteration 796, loss = 0.09145202\n",
      "Iteration 797, loss = 0.09123252\n",
      "Iteration 798, loss = 0.09105712\n",
      "Iteration 799, loss = 0.09090621\n",
      "Iteration 800, loss = 0.09073840\n",
      "Iteration 801, loss = 0.09055752\n",
      "Iteration 802, loss = 0.09036419\n",
      "Iteration 803, loss = 0.09015946\n",
      "Iteration 804, loss = 0.08999438\n",
      "Iteration 805, loss = 0.08983163\n",
      "Iteration 806, loss = 0.08962354\n",
      "Iteration 807, loss = 0.08946953\n",
      "Iteration 808, loss = 0.08931529\n",
      "Iteration 809, loss = 0.08914925\n",
      "Iteration 810, loss = 0.08896664\n",
      "Iteration 811, loss = 0.08876833\n",
      "Iteration 812, loss = 0.08859627\n",
      "Iteration 813, loss = 0.08844331\n",
      "Iteration 814, loss = 0.08824491\n",
      "Iteration 815, loss = 0.08808646\n",
      "Iteration 816, loss = 0.08793560\n",
      "Iteration 817, loss = 0.08776966\n",
      "Iteration 818, loss = 0.08759000\n",
      "Iteration 819, loss = 0.08739412\n",
      "Iteration 820, loss = 0.08726192\n",
      "Iteration 821, loss = 0.08711334\n",
      "Iteration 822, loss = 0.08692092\n",
      "Iteration 823, loss = 0.08671871\n",
      "Iteration 824, loss = 0.08657104\n",
      "Iteration 825, loss = 0.08640527\n",
      "Iteration 826, loss = 0.08622629\n",
      "Iteration 827, loss = 0.08607103\n",
      "Iteration 828, loss = 0.08591194\n",
      "Iteration 829, loss = 0.08572728\n",
      "Iteration 830, loss = 0.08556838\n",
      "Iteration 831, loss = 0.08540384\n",
      "Iteration 832, loss = 0.08524474\n",
      "Iteration 833, loss = 0.08507484\n",
      "Iteration 834, loss = 0.08494075\n",
      "Iteration 835, loss = 0.08477521\n",
      "Iteration 836, loss = 0.08459849\n",
      "Iteration 837, loss = 0.08444843\n",
      "Iteration 838, loss = 0.08428195\n",
      "Iteration 839, loss = 0.08413075\n",
      "Iteration 840, loss = 0.08396729\n",
      "Iteration 841, loss = 0.08379587\n",
      "Iteration 842, loss = 0.08364653\n",
      "Iteration 843, loss = 0.08347752\n",
      "Iteration 844, loss = 0.08332671\n",
      "Iteration 845, loss = 0.08316512\n",
      "Iteration 846, loss = 0.08302276\n",
      "Iteration 847, loss = 0.08286284\n",
      "Iteration 848, loss = 0.08270362\n",
      "Iteration 849, loss = 0.08255230\n",
      "Iteration 850, loss = 0.08238395\n",
      "Iteration 851, loss = 0.08225158\n",
      "Iteration 852, loss = 0.08210205\n",
      "Iteration 853, loss = 0.08192204\n",
      "Iteration 854, loss = 0.08179327\n",
      "Iteration 855, loss = 0.08165866\n",
      "Iteration 856, loss = 0.08150738\n",
      "Iteration 857, loss = 0.08133572\n",
      "Iteration 858, loss = 0.08115431\n",
      "Iteration 859, loss = 0.08106173\n",
      "Iteration 860, loss = 0.08093135\n",
      "Iteration 861, loss = 0.08075485\n",
      "Iteration 862, loss = 0.08055104\n",
      "Iteration 863, loss = 0.08043661\n",
      "Iteration 864, loss = 0.08031682\n",
      "Iteration 865, loss = 0.08017011\n",
      "Iteration 866, loss = 0.08000621\n",
      "Iteration 867, loss = 0.07982333\n",
      "Iteration 868, loss = 0.07962672\n",
      "Iteration 869, loss = 0.07954011\n",
      "Iteration 870, loss = 0.07942772\n",
      "Iteration 871, loss = 0.07927668\n",
      "Iteration 872, loss = 0.07908971\n",
      "Iteration 873, loss = 0.07888988\n",
      "Iteration 874, loss = 0.07878780\n",
      "Iteration 875, loss = 0.07868327\n",
      "Iteration 876, loss = 0.07855080\n",
      "Iteration 877, loss = 0.07839315\n",
      "Iteration 878, loss = 0.07821700\n",
      "Iteration 879, loss = 0.07802653\n",
      "Iteration 880, loss = 0.07789365\n",
      "Iteration 881, loss = 0.07778395\n",
      "Iteration 882, loss = 0.07764510\n",
      "Iteration 883, loss = 0.07747865\n",
      "Iteration 884, loss = 0.07728492\n",
      "Iteration 885, loss = 0.07717237\n",
      "Iteration 886, loss = 0.07706547\n",
      "Iteration 887, loss = 0.07693385\n",
      "Iteration 888, loss = 0.07677409\n",
      "Iteration 889, loss = 0.07659942\n",
      "Iteration 890, loss = 0.07642790\n",
      "Iteration 891, loss = 0.07630958\n",
      "Iteration 892, loss = 0.07615812\n",
      "Iteration 893, loss = 0.07600463\n",
      "Iteration 894, loss = 0.07587134\n",
      "Iteration 895, loss = 0.07571968\n",
      "Iteration 896, loss = 0.07561006\n",
      "Iteration 897, loss = 0.07548011\n",
      "Iteration 898, loss = 0.07532806\n",
      "Iteration 899, loss = 0.07516667\n",
      "Iteration 900, loss = 0.07503592\n",
      "Iteration 901, loss = 0.07488359\n",
      "Iteration 902, loss = 0.07474988\n",
      "Iteration 903, loss = 0.07461506\n",
      "Iteration 904, loss = 0.07447157\n",
      "Iteration 905, loss = 0.07434535\n",
      "Iteration 906, loss = 0.07419982\n",
      "Iteration 907, loss = 0.07409188\n",
      "Iteration 908, loss = 0.07396266\n",
      "Iteration 909, loss = 0.07381790\n",
      "Iteration 910, loss = 0.07366928\n",
      "Iteration 911, loss = 0.07354242\n",
      "Iteration 912, loss = 0.07339707\n",
      "Iteration 913, loss = 0.07329837\n",
      "Iteration 914, loss = 0.07317475\n",
      "Iteration 915, loss = 0.07302940\n",
      "Iteration 916, loss = 0.07286291\n",
      "Iteration 917, loss = 0.07273662\n",
      "Iteration 918, loss = 0.07259649\n",
      "Iteration 919, loss = 0.07246734\n",
      "Iteration 920, loss = 0.07234005\n",
      "Iteration 921, loss = 0.07220077\n",
      "Iteration 922, loss = 0.07207834\n",
      "Iteration 923, loss = 0.07193812\n",
      "Iteration 924, loss = 0.07183249\n",
      "Iteration 925, loss = 0.07170263\n",
      "Iteration 926, loss = 0.07155679\n",
      "Iteration 927, loss = 0.07145071\n",
      "Iteration 928, loss = 0.07132674\n",
      "Iteration 929, loss = 0.07118376\n",
      "Iteration 930, loss = 0.07103153\n",
      "Iteration 931, loss = 0.07091067\n",
      "Iteration 932, loss = 0.07077455\n",
      "Iteration 933, loss = 0.07064185\n",
      "Iteration 934, loss = 0.07052879\n",
      "Iteration 935, loss = 0.07039856\n",
      "Iteration 936, loss = 0.07027527\n",
      "Iteration 937, loss = 0.07014748\n",
      "Iteration 938, loss = 0.07000342\n",
      "Iteration 939, loss = 0.06990634\n",
      "Iteration 940, loss = 0.06978836\n",
      "Iteration 941, loss = 0.06965076\n",
      "Iteration 942, loss = 0.06948888\n",
      "Iteration 943, loss = 0.06936850\n",
      "Iteration 944, loss = 0.06923967\n",
      "Iteration 945, loss = 0.06911578\n",
      "Iteration 946, loss = 0.06899550\n",
      "Iteration 947, loss = 0.06886612\n",
      "Iteration 948, loss = 0.06875145\n",
      "Iteration 949, loss = 0.06862947\n",
      "Iteration 950, loss = 0.06848602\n",
      "Iteration 951, loss = 0.06835897\n",
      "Iteration 952, loss = 0.06825607\n",
      "Iteration 953, loss = 0.06813366\n",
      "Iteration 954, loss = 0.06799244\n",
      "Iteration 955, loss = 0.06789620\n",
      "Iteration 956, loss = 0.06778262\n",
      "Iteration 957, loss = 0.06764292\n",
      "Iteration 958, loss = 0.06749520\n",
      "Iteration 959, loss = 0.06737898\n",
      "Iteration 960, loss = 0.06724136\n",
      "Iteration 961, loss = 0.06715371\n",
      "Iteration 962, loss = 0.06703292\n",
      "Iteration 963, loss = 0.06689516\n",
      "Iteration 964, loss = 0.06677486\n",
      "Iteration 965, loss = 0.06666870\n",
      "Iteration 966, loss = 0.06652935\n",
      "Iteration 967, loss = 0.06640836\n",
      "Iteration 968, loss = 0.06630047\n",
      "Iteration 969, loss = 0.06616275\n",
      "Iteration 970, loss = 0.06604122\n",
      "Iteration 971, loss = 0.06593308\n",
      "Iteration 972, loss = 0.06580158\n",
      "Iteration 973, loss = 0.06568416\n",
      "Iteration 974, loss = 0.06557040\n",
      "Iteration 975, loss = 0.06543342\n",
      "Iteration 976, loss = 0.06533969\n",
      "Iteration 977, loss = 0.06522627\n",
      "Iteration 978, loss = 0.06509498\n",
      "Iteration 979, loss = 0.06495558\n",
      "Iteration 980, loss = 0.06487755\n",
      "Iteration 981, loss = 0.06477188\n",
      "Iteration 982, loss = 0.06465668\n",
      "Iteration 983, loss = 0.06451294\n",
      "Iteration 984, loss = 0.06436577\n",
      "Iteration 985, loss = 0.06426256\n",
      "Iteration 986, loss = 0.06413752\n",
      "Iteration 987, loss = 0.06402532\n",
      "Iteration 988, loss = 0.06391254\n",
      "Iteration 989, loss = 0.06377418\n",
      "Iteration 990, loss = 0.06365864\n",
      "Iteration 991, loss = 0.06355860\n",
      "Iteration 992, loss = 0.06343671\n",
      "Iteration 993, loss = 0.06331895\n",
      "Iteration 994, loss = 0.06320326\n",
      "Iteration 995, loss = 0.06309675\n",
      "Iteration 996, loss = 0.06297949\n",
      "Iteration 997, loss = 0.06285114\n",
      "Iteration 998, loss = 0.06273190\n",
      "Iteration 999, loss = 0.06263589\n",
      "Iteration 1000, loss = 0.06252050\n",
      "Iteration 1001, loss = 0.06242178\n",
      "Iteration 1002, loss = 0.06231438\n",
      "Iteration 1003, loss = 0.06218258\n",
      "Iteration 1004, loss = 0.06208502\n",
      "Iteration 1005, loss = 0.06197816\n",
      "Iteration 1006, loss = 0.06185552\n",
      "Iteration 1007, loss = 0.06173096\n",
      "Iteration 1008, loss = 0.06162287\n",
      "Iteration 1009, loss = 0.06150620\n",
      "Iteration 1010, loss = 0.06139844\n",
      "Iteration 1011, loss = 0.06130251\n",
      "Iteration 1012, loss = 0.06118489\n",
      "Iteration 1013, loss = 0.06109179\n",
      "Iteration 1014, loss = 0.06099022\n",
      "Iteration 1015, loss = 0.06086519\n",
      "Iteration 1016, loss = 0.06076628\n",
      "Iteration 1017, loss = 0.06067090\n",
      "Iteration 1018, loss = 0.06055095\n",
      "Iteration 1019, loss = 0.06044460\n",
      "Iteration 1020, loss = 0.06034453\n",
      "Iteration 1021, loss = 0.06023187\n",
      "Iteration 1022, loss = 0.06011401\n",
      "Iteration 1023, loss = 0.06000970\n",
      "Iteration 1024, loss = 0.05989850\n",
      "Iteration 1025, loss = 0.05979428\n",
      "Iteration 1026, loss = 0.05970117\n",
      "Iteration 1027, loss = 0.05958714\n",
      "Iteration 1028, loss = 0.05949063\n",
      "Iteration 1029, loss = 0.05938380\n",
      "Iteration 1030, loss = 0.05926410\n",
      "Iteration 1031, loss = 0.05916371\n",
      "Iteration 1032, loss = 0.05907392\n",
      "Iteration 1033, loss = 0.05895891\n",
      "Iteration 1034, loss = 0.05885654\n",
      "Iteration 1035, loss = 0.05875623\n",
      "Iteration 1036, loss = 0.05864677\n",
      "Iteration 1037, loss = 0.05854258\n",
      "Iteration 1038, loss = 0.05844669\n",
      "Iteration 1039, loss = 0.05833442\n",
      "Iteration 1040, loss = 0.05824045\n",
      "Iteration 1041, loss = 0.05814160\n",
      "Iteration 1042, loss = 0.05801938\n",
      "Iteration 1043, loss = 0.05795606\n",
      "Iteration 1044, loss = 0.05786653\n",
      "Iteration 1045, loss = 0.05775788\n",
      "Iteration 1046, loss = 0.05763134\n",
      "Iteration 1047, loss = 0.05753154\n",
      "Iteration 1048, loss = 0.05745319\n",
      "Iteration 1049, loss = 0.05734204\n",
      "Iteration 1050, loss = 0.05721047\n",
      "Iteration 1051, loss = 0.05715604\n",
      "Iteration 1052, loss = 0.05707814\n",
      "Iteration 1053, loss = 0.05697498\n",
      "Iteration 1054, loss = 0.05685339\n",
      "Iteration 1055, loss = 0.05671668\n",
      "Iteration 1056, loss = 0.05665458\n",
      "Iteration 1057, loss = 0.05658252\n",
      "Iteration 1058, loss = 0.05648560\n",
      "Iteration 1059, loss = 0.05636291\n",
      "Iteration 1060, loss = 0.05621993\n",
      "Iteration 1061, loss = 0.05616314\n",
      "Iteration 1062, loss = 0.05609573\n",
      "Iteration 1063, loss = 0.05599577\n",
      "Iteration 1064, loss = 0.05587540\n",
      "Iteration 1065, loss = 0.05573696\n",
      "Iteration 1066, loss = 0.05565741\n",
      "Iteration 1067, loss = 0.05559088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1068, loss = 0.05549363\n",
      "Iteration 1069, loss = 0.05537081\n",
      "Iteration 1070, loss = 0.05523665\n",
      "Iteration 1071, loss = 0.05516010\n",
      "Iteration 1072, loss = 0.05505647\n",
      "Iteration 1073, loss = 0.05495686\n",
      "Iteration 1074, loss = 0.05486275\n",
      "Iteration 1075, loss = 0.05476439\n",
      "Iteration 1076, loss = 0.05466501\n",
      "Iteration 1077, loss = 0.05457583\n",
      "Iteration 1078, loss = 0.05447801\n",
      "Iteration 1079, loss = 0.05438322\n",
      "Iteration 1080, loss = 0.05428924\n",
      "Iteration 1081, loss = 0.05418069\n",
      "Iteration 1082, loss = 0.05408657\n",
      "Iteration 1083, loss = 0.05400282\n",
      "Iteration 1084, loss = 0.05390478\n",
      "Iteration 1085, loss = 0.05381866\n",
      "Iteration 1086, loss = 0.05372711\n",
      "Iteration 1087, loss = 0.05361773\n",
      "Iteration 1088, loss = 0.05355197\n",
      "Iteration 1089, loss = 0.05346748\n",
      "Iteration 1090, loss = 0.05335698\n",
      "Iteration 1091, loss = 0.05324668\n",
      "Iteration 1092, loss = 0.05316291\n",
      "Iteration 1093, loss = 0.05305651\n",
      "Iteration 1094, loss = 0.05298968\n",
      "Iteration 1095, loss = 0.05290186\n",
      "Iteration 1096, loss = 0.05279692\n",
      "Iteration 1097, loss = 0.05269692\n",
      "Iteration 1098, loss = 0.05261395\n",
      "Iteration 1099, loss = 0.05251271\n",
      "Iteration 1100, loss = 0.05241946\n",
      "Iteration 1101, loss = 0.05233125\n",
      "Iteration 1102, loss = 0.05222011\n",
      "Iteration 1103, loss = 0.05216291\n",
      "Iteration 1104, loss = 0.05208248\n",
      "Iteration 1105, loss = 0.05197933\n",
      "Iteration 1106, loss = 0.05186437\n",
      "Iteration 1107, loss = 0.05180531\n",
      "Iteration 1108, loss = 0.05173673\n",
      "Iteration 1109, loss = 0.05163763\n",
      "Iteration 1110, loss = 0.05151796\n",
      "Iteration 1111, loss = 0.05143297\n",
      "Iteration 1112, loss = 0.05135535\n",
      "Iteration 1113, loss = 0.05125150\n",
      "Iteration 1114, loss = 0.05113646\n",
      "Iteration 1115, loss = 0.05109539\n",
      "Iteration 1116, loss = 0.05102388\n",
      "Iteration 1117, loss = 0.05092468\n",
      "Iteration 1118, loss = 0.05080848\n",
      "Iteration 1119, loss = 0.05071564\n",
      "Iteration 1120, loss = 0.05064702\n",
      "Iteration 1121, loss = 0.05055637\n",
      "Iteration 1122, loss = 0.05044657\n",
      "Iteration 1123, loss = 0.05035177\n",
      "Iteration 1124, loss = 0.05027961\n",
      "Iteration 1125, loss = 0.05017840\n",
      "Iteration 1126, loss = 0.05008920\n",
      "Iteration 1127, loss = 0.05001217\n",
      "Iteration 1128, loss = 0.04991403\n",
      "Iteration 1129, loss = 0.04981927\n",
      "Iteration 1130, loss = 0.04973822\n",
      "Iteration 1131, loss = 0.04963819\n",
      "Iteration 1132, loss = 0.04955216\n",
      "Iteration 1133, loss = 0.04947479\n",
      "Iteration 1134, loss = 0.04938561\n",
      "Iteration 1135, loss = 0.04929880\n",
      "Iteration 1136, loss = 0.04921023\n",
      "Iteration 1137, loss = 0.04913308\n",
      "Iteration 1138, loss = 0.04904593\n",
      "Iteration 1139, loss = 0.04894405\n",
      "Iteration 1140, loss = 0.04886268\n",
      "Iteration 1141, loss = 0.04878737\n",
      "Iteration 1142, loss = 0.04869550\n",
      "Iteration 1143, loss = 0.04862086\n",
      "Iteration 1144, loss = 0.04853792\n",
      "Iteration 1145, loss = 0.04843875\n",
      "Iteration 1146, loss = 0.04837990\n",
      "Iteration 1147, loss = 0.04830115\n",
      "Iteration 1148, loss = 0.04820598\n",
      "Iteration 1149, loss = 0.04810972\n",
      "Iteration 1150, loss = 0.04803500\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy: 0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "#Import the classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "##Creating an instance of a MLP classifier\n",
    "#and setting it some option (max mum epoch, verbose on, activation of neurons)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(16, 8), max_iter=2000, activation='relu', verbose=True)\n",
    "\n",
    "#train the model\n",
    "mlp.fit(feat_train, lab_train)\n",
    "\n",
    "#applying the the model on the test data (features)\n",
    "lab_predict = mlp.predict(feat_test)\n",
    "print('Accuracy:',sklearn.metrics.accuracy_score(lab_test, lab_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "81b2bf9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled samples 3 out of 51\n",
      "Accuracy: 0.9411764705882353\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      1.00      0.92        12\n",
      "         1.0       1.00      0.94      0.97        16\n",
      "         2.0       1.00      0.91      0.95        11\n",
      "         3.0       0.92      0.92      0.92        12\n",
      "\n",
      "    accuracy                           0.94        51\n",
      "   macro avg       0.94      0.94      0.94        51\n",
      "weighted avg       0.95      0.94      0.94        51\n",
      "\n",
      "confusion matrix\n",
      "[[12  0  0  0]\n",
      " [ 0 15  0  1]\n",
      " [ 1  0 10  0]\n",
      " [ 1  0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "#plotting the loss curve over training iteration \n",
    "plt.plot(mlp.loss_curve_)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n",
    "\n",
    "#print the number of misclassified samples, accuracy and complete report (using scikit learn metric tools) \n",
    "print('Number of mislabeled samples %d out of %d' % ((lab_test != lab_predict).sum(),lab_test.size))\n",
    "print('Accuracy:',sklearn.metrics.accuracy_score(lab_test, lab_predict))\n",
    "print(sklearn.metrics.classification_report(lab_test, lab_predict))\n",
    "print('confusion matrix')\n",
    "print(sklearn.metrics.confusion_matrix(lab_test,lab_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b94ad942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#defining a function for the confusion matrix display, from Stefano Fasciani\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = sklearn.metrics.confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    #classes = classes[sklearn.utils.multiclass.unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "       # print(\"Normalized confusion matrix\")\n",
    "    \n",
    "    #print(cm)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "#setting the precision to two digits after the decimal point\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(lab_test, lab_predict, classes=classes,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(lab_test, lab_predict, classes=classes, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eeefc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcefaad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
